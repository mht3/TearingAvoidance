{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tearing Avoidance Policy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "data_dir = os.path.join('..', 'data')\n",
    "tm_avoidance_dir = os.path.join('..', 'tm_avoidance_model')\n",
    "\n",
    "# load simulator\n",
    "sys.path.insert(0, '..')\n",
    "from tm_avoidance_model import Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIII-D Data\n",
    "\n",
    "- x0: **0D Parameters**. This includes magnetic signals and actuators. There are 11 in total.\n",
    "- x1: **1D Plasma Profiles**: One-dimensional kinetic and magnetic profiles mapped in a magnetic flux coordinate. The profiles aree electron density, electron temperature, ion rotation, safety factor, and plasma pressure. v Ie 5 plasma profiles mapped on 33 grids. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0 mean: (11,)\n",
      "x1 mean: (33, 5)\n"
     ]
    }
   ],
   "source": [
    "# x0 metrics\n",
    "x0_mean_path = os.path.join(tm_avoidance_dir, 'x0_mean.npy')\n",
    "x0_mean = np.load(x0_mean_path)\n",
    "x0_std_path = os.path.join(tm_avoidance_dir, 'x0_std.npy')\n",
    "x0_std = np.load(x0_std_path)\n",
    "print(\"x0 mean:\", x0_mean.shape)\n",
    "# x1 metrics\n",
    "x1_mean_path = os.path.join(tm_avoidance_dir, 'x1_mean.npy')\n",
    "x1_mean = np.load(x1_mean_path)\n",
    "x1_std_path = os.path.join(tm_avoidance_dir, 'x1_std.npy')\n",
    "x1_std = np.load(x1_std_path)\n",
    "print(\"x1 mean:\", x1_mean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation/State Space\n",
    "\n",
    "The observation is a 33x5 plasma profile which can take values in the range [-2, 2].\n",
    "\n",
    "The 5 values represent ne, te, 1/q, pres, rot.\n",
    "\n",
    "- **ne**: electron density\n",
    "- **te**: electron temperature\n",
    "- **$\\frac{1}{q}$**: one divided by the safety factor (q)\n",
    "- **pres**: plasma pressure \n",
    "- **rot**: ion rotation\n",
    "```python\n",
    "self.observation_space = gym.spaces.Box(\n",
    "    low = -2 * np.ones_like(self.x1_mean), # Shape: (33, 5)\n",
    "    high = 2 * np.ones_like(self.x1_mean), # Shape: (33, 5)\n",
    "    dtype = np.float32\n",
    ")\n",
    "```\n",
    "\n",
    "The state is also size 33x5 and is generated by picking a (33x5) element from one of the N samples in the dataset.\n",
    "```python\n",
    "self.idx = np.random.randint(len(self.x0))\n",
    "(self.x1[self.idx] - s_mean) / s_std\n",
    "```\n",
    "where $s_{mean}$ and $s_{std}$ are the mean and standard deviation of the state (ne, te, 1/q, pres, rot): \n",
    "```python\n",
    "s_mean = np.array([3.977, 1.587, 0.5103, 23303., 42.93])\n",
    "s_std = np.array([2.764, 1.560, 0.4220, 35931., 58.47])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action Space\n",
    "\n",
    "The actions are the **total beam power and plasma top triangularity**. Other actuators on the tokamak are assumed to be fixed. The plasma control system (PCS) holds these other actuators such as beam torque, plasma current, bottom triangularity and plasma elongation. These are fixed in order to maintain a $q_{95}\\approx 3$ for ITER baseline conditions.\n",
    "\n",
    "I still am uncertain why the code has 3 actions when the paper mentions only 2. The third action is bottom triangularity which the authors say are fixed in their nature paper. \n",
    "\n",
    "```python\n",
    "a_mean = np.array([4072.8761393229165, 0.6, 0.41])\n",
    "a_std = np.array([3145.5935872395835, 0.31, 0.31])\n",
    "\n",
    "```\n",
    "Actions correspond to beam power ('pinj'), top triangularity ('tritop_EFIT01'), and bottom triangularity ('tribot_EFIT01')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic (Reward) Model\n",
    "\n",
    "The reward model is defined mostly by the dynamic model, a supervised DNN that predicts $\\beta_n$ and tearability.\n",
    "\n",
    "The dynamic model is NOT a simulator that predicts the next state given a current state and action.\n",
    "\n",
    "Below is pseudocode giving the general idea of what the model is doing.\n",
    "\n",
    "#### labels for inputs and outputs of reward model\n",
    "```python\n",
    "# at t+dt (pinj and tinj both define injected power and injected torque)\n",
    "inputs_0d = ['bt', 'ip', 'pinj', 'tinj', 'R0_EFITRT1', 'kappa_EFITRT1', 'tritop_EFIT01', 'tribot_EFIT01', 'gapin_EFIT01', 'ech_pwr_total', 'EC.RHO_ECH']\n",
    "# at t\n",
    "inputs_1d = ['thomson_density_mtanh_1d', 'thomson_temp_mtanh_1d', '1/qpsi_EFITRT1', 'pres_EFIT01', 'cer_rot_csaps_1d']\n",
    "# at t+dt\n",
    "outputs = ['betan_EFITRT1', 'tm_label']\n",
    "```\n",
    "\n",
    "```!Python\n",
    "define state, action\n",
    "# Define tearability threshold\n",
    "threshold = 0.5\n",
    "# Predict next step\n",
    "y = dynamic_model.predict(state, action)\n",
    "betan, tearability = y[0][0], sigmoid(y[1][0])\n",
    "# Estimate reward\n",
    "if tearability < threshold:\n",
    "    reward = betan\n",
    "else:\n",
    "    reward = threshold - tearability\n",
    "\n",
    "```\n",
    "\n",
    "This is a KNOWN model (trained neural network) and is only used to determine the reward for the given (s, a) pair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### environment: step function\n",
    "\n",
    "The step() function should transition to a new state based on an action, but it does not.\n",
    "Instead, the observation is **randomly sampled from experimental data**.\n",
    "\n",
    "```python\n",
    "\n",
    "# index is randomly sampled in the reset function after each step because step returns done=True   \n",
    "self.idx = np.random.randint(len(self.x0))\n",
    "\n",
    "def step(self, action):\n",
    "    # Take action\n",
    "    action1 = np.clip(action * a_std + a_mean, clip_action1, clip_action2)\n",
    "    x0_tmp, x1_tmp = self.x0[[self.idx]].copy(), self.x1[[self.idx]].copy()\n",
    "    x0_tmp[0, 2] = action1[0]\n",
    "    x0_tmp[0, 3] = min(1.0, action1[0] * self.x0_mean[3] / self.x0_mean[2])\n",
    "    x0_tmp[0, 6] = action1[1]\n",
    "    x0_tmp[0, 7] = action1[2]\n",
    "\n",
    "    # Predict next step\n",
    "    y = self.predictors[self.i_model].predict([x0_tmp, x1_tmp])\n",
    "    betan, tearability = y[0][0], sigmoid(y[1][0])\n",
    "\n",
    "    # Estimate reward\n",
    "    if tearability < threshold:\n",
    "        reward = betan\n",
    "    else:\n",
    "        reward = threshold - tearability\n",
    "    print(self.episodes, action[0], betan, tearability, reward)\n",
    "    return (self.x1[self.idx] - s_mean) / s_std, reward, True, {}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate Original DIII-D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_tokamak_data(n, mu_0, sigma_0, mu_1, sigma_1):\n",
    "    '''\n",
    "    Simulate DIII-D data based upon calculated mean and standard deviations of x0 and x1 from Seo et al.\n",
    "    Parameters:\n",
    "        n (int):\n",
    "            total number of samples\n",
    "        mu_0 (np.array):\n",
    "            mean of 0D parameters from dataset. Shape = (11,)\n",
    "        sigma_0 (np.array):\n",
    "            standard deviation of 0D parameters from dataset. Shape = (11,)\n",
    "        mu_1 (np.array):\n",
    "            mean of plasma profile from dataset. Shape = (33, 5)\n",
    "        sigma_1 (np.array):\n",
    "            standard deviation of 0D parameters from dataset. Shape = (33, 5)\n",
    "    '''\n",
    "    x0 = np.random.normal(loc=mu_0, scale=sigma_0, size=(n, mu_0.shape[0]))\n",
    "    x1 = np.random.normal(loc=mu_1, scale=sigma_1, size=(n, mu_1.shape[0], mu_1.shape[1]))\n",
    "    return x0, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0D Parameters: (10000, 11)\n",
      "1D Plasma Profile: (10000, 33, 5)\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "simulated_x0, simulated_x1 = simulate_tokamak_data(N, x0_mean, x0_std, x1_mean, x1_std)\n",
    "print('0D Parameters:', simulated_x0.shape)\n",
    "\n",
    "print('1D Plasma Profile:', simulated_x1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load environment with simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step\n",
      "313/313 [==============================] - 2s 4ms/step\n",
      "313/313 [==============================] - 2s 4ms/step\n",
      "313/313 [==============================] - 2s 4ms/step\n",
      "313/313 [==============================] - 2s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "env = Env(x0_data=simulated_x0, x1_data=simulated_x1)\n",
    "s = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "reward -0.4615461693020966\n",
      "Episode Terminated: True\n",
      "Testing if step function is deterministic given state and action\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "reward -0.4615461693020966\n",
      "Episode Terminated: True\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.5, 0.5, 0.5])\n",
    "s_prime, reward, done, info = env.step(a)\n",
    "print(\"reward\", reward)\n",
    "print(\"Episode Terminated:\", done)\n",
    "print(\"Testing if step function is deterministic given state and action\")\n",
    "s_prime, reward, done, info = env.step(a)\n",
    "print(\"reward\", reward)\n",
    "print(\"Episode Terminated:\", done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tearability predictor (reward model)\n",
    "\n",
    "This is what is happening under the hood during an episode. An episode in this work is defined as a single step because random samples are drawn from the dataset to get to the next state (independent of current state and action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "WARNING:tensorflow:5 out of the last 319 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020352753C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 466ms/step\n",
      "WARNING:tensorflow:6 out of the last 320 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000203528F51F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 399ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "import math\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    '''\n",
    "    Requires function for f1 score to load model. Only used for the dynamic model training.\n",
    "    '''\n",
    "    return 1.0\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+math.e**(-z))\n",
    "\n",
    "# get random sample from generated dataset\n",
    "idx = np.random.randint(len(simulated_x0))\n",
    "predictor_dir = os.path.abspath(os.path.join('..', 'tm_prediction_model'))\n",
    "threshold = 0.5\n",
    "#  Load model from folder with TensorFlow's Protocol Buffer files\n",
    "predictors = [models.load_model(os.path.join(predictor_dir, f'best_model_{i}'), custom_objects={'f1_m':f1_m}) for i in range(5)]\n",
    "y = np.mean([p.predict([simulated_x0[[idx]], simulated_x1[[idx]]]) for p in predictors], axis=0)\n",
    "beta_n, tearability = y[0][0], sigmoid(y[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_n: 1.3993876\n",
      "tearability: 0.0013292713030323977\n",
      "reward: 1.3993876\n"
     ]
    }
   ],
   "source": [
    "print(\"beta_n:\", beta_n)\n",
    "print(\"tearability:\", tearability)\n",
    "\n",
    "# Estimate reward\n",
    "if tearability < threshold:\n",
    "    reward = beta_n\n",
    "else:\n",
    "    reward = threshold - tearability\n",
    "\n",
    "print(\"reward:\", reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
